---
title: "AI Ethics Scenarios"
format: html
editor: source
toc: true
toc-depth: 3
---

If you were in a position where you could decide if the organization would use the program or not, then what would you decide to do? Why?

## Considerations

Consider the following questions when making your decision about each of the scenarios:

### Business Understanding
* How diverse and familiar with the development context are the group of people defining the problem?


### Data Understanding
* What might need to be done to improve representativeness of data?

### Data Preparation
* What are the protected attributes for this context or problem?

### Modeling
* What potential biases will the algorithm introduce?
* How well can individual decisions or predictions be explained in human-friendly terms?

### Evaluation
* How can you best implement fairness?
* What tradeoff between model accuracy and equity is appropriate for my context?

### Deployment
* Given the equity of outcomes in practice, representativeness, and explainability, how will model predictions be used in practice?
* What mechanisms will be put into place to audit models over time and enhance accountability for model results?


## Scenarios

### Scenario #1: Hiring Practices
An organization is overwhelmed by the number of applicants that it is receiving for the roles that it has posted.

In an effort to make it easier to hire candidates, a team of data scientists has built a machine learning model that will determine whether or not a candidate should be hired based upon their resume.

Some personally identifiable information, such as the name of the candidate were not considered as a feature of the model.

### Scenario #2: Regulation Navigation
Your organization helps people navigate the complex web of regulations that govern their lives. In an effort to make it easier for your community to find the regulation that is most meaningful for them, your team has launched a chatbot to help guide people to the appropriate information seamlessly.

You limit the information that the chatbot is allowed to consider in its responses, focusing specifically on regulations for organizational operations.


### Scenario #3: Child Protection
Child welfare workers are asked to make thousands of decisions in any given year. This is an overwhelming number of decisions to make - often with imperfect information. A county’s Department of Health and Human Services built a model that can aid decision making for its child welfare workers. Each case is given a score that indicates how risky it is based upon the likelihood of the child to be removed from the home within 2 years.

Incidents of potential neglect are reported to the county’s child protection hotline. The reports go through a screening process where the algorithm calculates the child’s potential risk and assigns a score. Child welfare  workers then use their discretion to decide whether to investigate.


### Scenario #4: Recidivism
Judges make decisions about the sentences that criminals receive. One of the factors that judges consider during sentencing is the likelihood of the person to re-offend (recidivism).

Courtrooms have adopted tools designed to eliminate bias in sentencing through the use of artificial intelligence. The history of the criminal can be input into the model. It will then output the likelihood of the person to re-offend.

Demographic information about the criminal is not included in the model.
